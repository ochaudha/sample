{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "RNN.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ochaudha/sample/blob/main/RNN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of the Code:\n",
        "\n",
        "Configuration: Sets up constants like HIDDEN_SIZE, LEARNING_RATE, NUM_EPOCHS, and selects the device (cpu by default for broad compatibility). MAX_LENGTH is crucial for fixed-size tensors.\n",
        "\n",
        "Data Preparation (Lang Class):\n",
        "\n",
        "The Lang class helps build character-to-index (char2idx) and index-to-character (idx2char) mappings for both English (Roman) and Hindi (Devanagari) alphabets.\n",
        "\n",
        "It includes special tokens: <SOS> (Start Of Sequence), <EOS> (End Of Sequence), and <PAD> (Padding) for sequence handling.\n",
        "\n",
        "tensor_from_text: A helper function to convert a string into a padded PyTorch tensor of character indices, adding the <EOS> token.\n",
        "\n",
        "Model Architecture:\n",
        "\n",
        "EncoderRNN:\n",
        "\n",
        "Takes an input character index, converts it to an embedding vector using nn.Embedding.\n",
        "\n",
        "Processes the embedded character using a nn.GRU (Gated Recurrent Unit), which outputs an output (per time step) and a hidden state (the context of the sequence so far).\n",
        "\n",
        "init_hidden() provides an initial zero hidden state.\n",
        "\n",
        "AttnDecoderRNN:\n",
        "\n",
        "Also uses nn.Embedding for output characters.\n",
        "\n",
        "Attention (self.attn, self.attn_combine): This is the core of the attention mechanism.\n",
        "\n",
        "It calculates attn_weights by looking at the current decoder input embedding and its hidden state, and comparing them against all encoder outputs. F.softmax normalizes these weights.\n",
        "\n",
        "attn_applied is the weighted sum of encoder outputs, allowing the decoder to focus on relevant input parts.\n",
        "\n",
        "This attn_applied context vector is concatenated with the current embedded input before being fed into the GRU.\n",
        "\n",
        "nn.GRU: Processes the combined input and attention context.\n",
        "\n",
        "nn.Linear: Projects the GRU's output to the size of the output vocabulary.\n",
        "\n",
        "F.log_softmax: Converts the linear output into log-probabilities over the next possible characters.\n",
        "\n",
        "Training Function (train):\n",
        "\n",
        "Initializes encoder's hidden state.\n",
        "\n",
        "Zeroes gradients for both optimizers.\n",
        "\n",
        "Encoder Loop: Iterates through the input characters, feeding each into the encoder to get encoder_outputs (all encoder hidden states, which attention will use) and the final encoder_hidden state (the context vector for the decoder).\n",
        "\n",
        "Decoder Loop:\n",
        "\n",
        "Starts with <SOS> token as input and the encoder_hidden state.\n",
        "\n",
        "Teacher Forcing: A technique where, during training, the decoder is sometimes fed the actual next character from the target sequence instead of its own prediction. This helps the model learn faster and more stably in early stages. TEACHER_FORCING_RATIO controls how often this happens.\n",
        "\n",
        "At each step, it predicts the next character, calculates loss against the true target character.\n",
        "\n",
        "Continues until <EOS> is predicted or MAX_LENGTH is reached.\n",
        "\n",
        "loss.backward(): Computes gradients.\n",
        "\n",
        "optimizer.step(): Updates model weights.\n",
        "\n",
        "Returns the average loss per target character.\n",
        "\n",
        "Evaluation/Inference Function (evaluate):\n",
        "\n",
        "Sets models to eval() mode (with torch.no_grad()) to disable gradient calculation and dropout.\n",
        "\n",
        "Similar to the training decoder loop, but it always feeds the decoder's own predicted character as the next input (no teacher forcing).\n",
        "\n",
        "Collects decoded characters until <EOS> or MAX_LENGTH is reached.\n",
        "\n",
        "Main Execution (if __name__ == \"__main__\":)\n",
        "\n",
        "Initializes encoder and decoder models, optimizers, and the nn.NLLLoss criterion (Negative Log Likelihood Loss, which works with LogSoftmax output). ignore_index=PAD_token ensures padding tokens don't contribute to the loss.\n",
        "\n",
        "Runs the training loop for NUM_EPOCHS, randomly selecting a training_pair for each epoch.\n",
        "\n",
        "Prints loss and sample translations periodically to monitor progress.\n",
        "\n",
        "After training, it tests the model on a few specific names, including \"Omveer\" and \"NonExistent\" to see how it generalizes (or fails to).\n",
        "\n",
        "This sample provides a foundational understanding of how a character-level sequence-to-sequence model can be built in PyTorch for tasks like transliteration. For production-ready systems, you would need much larger datasets, more complex architectures (e.g., attention variants, deeper LSTMs/Transformers), and more sophisticated training techniques."
      ],
      "metadata": {
        "id": "Ee_DyPTjYI6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "# You can uncomment and modify these if you have a GPU\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\") # For broader compatibility\n",
        "\n",
        "# Hyperparameters\n",
        "HIDDEN_SIZE = 256\n",
        "EMBEDDING_DIM = 64\n",
        "LEARNING_RATE = 0.005\n",
        "NUM_EPOCHS = 3000\n",
        "MAX_LENGTH = 15 # Max characters in a name (e.g., \"Omveer\" is 6, \"Rahul\" is 5)\n",
        "TEACHER_FORCING_RATIO = 0.5 # For training stability\n",
        "\n",
        "# --- 2. Data Preparation ---\n",
        "\n",
        "# Tiny dataset of Roman script names and their Hindi transliterations\n",
        "# In a real scenario, this would be a much larger dataset.\n",
        "training_pairs = [\n",
        "    (\"Omveer\", \"ओमवीर\"),\n",
        "    (\"Rahul\", \"राहुल\"),\n",
        "    (\"Priya\", \"प्रिया\"),\n",
        "    (\"Amit\", \"अमित\"),\n",
        "    (\"Saurabh\", \"सौरभ\"),\n",
        "    (\"Deepak\", \"दीपक\"),\n",
        "    (\"Anjali\", \"अंजलि\"),\n",
        "    (\"Kavita\", \"कविता\"),\n",
        "    (\"Nitin\", \"नितिन\"),\n",
        "    (\"Sneha\", \"स्नेहा\"),\n",
        "    (\"Vivek\", \"विवेक\"),\n",
        "    (\"Pooja\", \"पूजा\"),\n",
        "    (\"Mohan\", \"मोहन\"),\n",
        "    (\"Ritu\", \"ऋतु\"),\n",
        "    (\"Gaurav\", \"गौरव\"),\n",
        "    (\"Preeti\", \"प्रीति\"),\n",
        "    (\"Rakesh\", \"राकेश\"),\n",
        "    (\"Seema\", \"सीमा\"),\n",
        "    (\"Vijay\", \"विजय\"),\n",
        "    (\"Sarita\", \"सरिता\"),\n",
        "    (\"Omveer Singh\", \"ओमवीर सिंह\") # A slightly longer example\n",
        "]\n",
        "\n",
        "# Special tokens\n",
        "SOS_token = 0  # Start Of Sequence\n",
        "EOS_token = 1  # End Of Sequence\n",
        "PAD_token = 2  # Padding\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.char2idx = {}\n",
        "        self.idx2char = {0: \"<SOS>\", 1: \"<EOS>\", 2: \"<PAD>\"}\n",
        "        self.n_chars = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for char in sentence:\n",
        "            self.add_char(char)\n",
        "\n",
        "    def add_char(self, char):\n",
        "        if char not in self.char2idx:\n",
        "            self.char2idx[char] = self.n_chars\n",
        "            self.idx2char[self.n_chars] = char\n",
        "            self.n_chars += 1\n",
        "\n",
        "# Build separate language objects for input (English) and output (Hindi)\n",
        "input_lang = Lang('eng')\n",
        "output_lang = Lang('hin')\n",
        "\n",
        "for eng, hin in training_pairs:\n",
        "    input_lang.add_sentence(eng)\n",
        "    output_lang.add_sentence(hin)\n",
        "\n",
        "print(f\"Input vocabulary size: {input_lang.n_chars}\")\n",
        "print(f\"Output vocabulary size: {output_lang.n_chars}\")\n",
        "\n",
        "# Helper to convert text to indices tensor, with padding\n",
        "def tensor_from_text(lang, text, max_length=MAX_LENGTH):\n",
        "    indices = [lang.char2idx[char] for char in text]\n",
        "    indices.append(EOS_token) # Add EOS token\n",
        "    if len(indices) > max_length: # Truncate if too long\n",
        "        indices = indices[:max_length-1] + [EOS_token]\n",
        "    padded_indices = indices + [PAD_token] * (max_length - len(indices)) # Pad\n",
        "    return torch.tensor(padded_indices, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "# --- 3. Model Architecture ---\n",
        "\n",
        "# Encoder\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, embedding_dim):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "# Decoder with Attention\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, embedding_dim, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, embedding_dim)\n",
        "        self.attn = nn.Linear(embedding_dim + hidden_size, self.max_length) # Attention weights\n",
        "        self.attn_combine = nn.Linear(embedding_dim + hidden_size, hidden_size) # Combine attended context and embedding\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        # Attention mechanism\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        # Combine embedded input and attended context\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "\n",
        "# --- 4. Training Function ---\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    # Encoder pass\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # Teacher forcing: Use the real target as next input\n",
        "    use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "    else:\n",
        "        # Without teacher forcing: Use its own prediction as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # Detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "# --- 5. Evaluation / Inference Function ---\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensor_from_text(input_lang, sentence)\n",
        "        input_length = input_tensor.size(0)\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_chars = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_chars.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_chars.append(output_lang.idx2char[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return ''.join(decoded_chars)\n",
        "\n",
        "# --- 6. Main Execution ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize models\n",
        "    encoder = EncoderRNN(input_lang.n_chars, HIDDEN_SIZE, EMBEDDING_DIM).to(device)\n",
        "    decoder = AttnDecoderRNN(output_lang.n_chars, HIDDEN_SIZE, EMBEDDING_DIM, dropout_p=0.1, max_length=MAX_LENGTH).to(device)\n",
        "\n",
        "    # Optimizers\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=LEARNING_RATE)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.NLLLoss(ignore_index=PAD_token) # NLLLoss with LogSoftmax output, ignore padding\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        # Pick a random training pair for simplicity\n",
        "        input_text, target_text = random.choice(training_pairs)\n",
        "\n",
        "        input_tensor = tensor_from_text(input_lang, input_text).to(device)\n",
        "        target_tensor = tensor_from_text(output_lang, target_text).to(device)\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "\n",
        "        if epoch % 500 == 0:\n",
        "            print(f\"Epoch {epoch}/{NUM_EPOCHS}, Loss: {loss:.4f}\")\n",
        "            # Evaluate some examples during training\n",
        "            print(f\"  Input: {input_text} -> Predicted: {evaluate(encoder, decoder, input_text)}\")\n",
        "            print(f\"  Input: Omveer -> Predicted: {evaluate(encoder, decoder, 'Omveer')}\")\n",
        "            print(f\"  Input: Rahul -> Predicted: {evaluate(encoder, decoder, 'Rahul')}\")\n",
        "            print(\"-\" * 20)\n",
        "\n",
        "    print(\"\\nTraining complete! Testing specific examples:\")\n",
        "    test_names = [\"Omveer\", \"Rahul\", \"Priya\", \"Saurabh\", \"Anjali\", \"Omveer Singh\", \"NonExistent\"]\n",
        "    for name in test_names:\n",
        "        print(f\"'{name}' -> '{evaluate(encoder, decoder, name)}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iHcQkJP7W6i_",
        "outputId": "7f6baef3-70e2-4822-ff89-9d5b54ea81a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input vocabulary size: 34\n",
            "Output vocabulary size: 33\n",
            "Starting training...\n",
            "Epoch 500/3000, Loss: nan\n",
            "  Input: Pooja -> Predicted: पूजा<EOS>\n",
            "  Input: Omveer -> Predicted: दममी<EOS>\n",
            "  Input: Rahul -> Predicted: राजु<EOS>\n",
            "--------------------\n",
            "Epoch 1000/3000, Loss: 0.0008\n",
            "  Input: Sneha -> Predicted: स्नेहा<EOS>\n",
            "  Input: Omveer -> Predicted: ओमवीर<EOS>\n",
            "  Input: Rahul -> Predicted: राहुल<EOS>\n",
            "--------------------\n",
            "Epoch 1500/3000, Loss: 0.0003\n",
            "  Input: Rahul -> Predicted: राहुल<EOS>\n",
            "  Input: Omveer -> Predicted: ओमवीर<EOS>\n",
            "  Input: Rahul -> Predicted: राहुल<EOS>\n",
            "--------------------\n",
            "Epoch 2000/3000, Loss: nan\n",
            "  Input: Vivek -> Predicted: विवेक<EOS>\n",
            "  Input: Omveer -> Predicted: ओमवीर<EOS>\n",
            "  Input: Rahul -> Predicted: राहुल<EOS>\n",
            "--------------------\n",
            "Epoch 2500/3000, Loss: 0.0001\n",
            "  Input: Gaurav -> Predicted: गौरव<EOS>\n",
            "  Input: Omveer -> Predicted: ओमवीर<EOS>\n",
            "  Input: Rahul -> Predicted: राहुल<EOS>\n",
            "--------------------\n",
            "Epoch 3000/3000, Loss: nan\n",
            "  Input: Preeti -> Predicted: प्रीति<EOS>\n",
            "  Input: Omveer -> Predicted: ओमवीर<EOS>\n",
            "  Input: Rahul -> Predicted: राहुल<EOS>\n",
            "--------------------\n",
            "\n",
            "Training complete! Testing specific examples:\n",
            "'Omveer' -> 'ओमवीर<EOS>'\n",
            "'Rahul' -> 'राहुल<EOS>'\n",
            "'Priya' -> 'प्रिया<EOS>'\n",
            "'Saurabh' -> 'सौरभ<EOS>'\n",
            "'Anjali' -> 'अंजलि<EOS>'\n",
            "'Omveer Singh' -> 'ओमवीर सिंह<EOS>'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'E'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2885624437.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0mtest_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Omveer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Rahul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Priya\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Saurabh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Anjali\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Omveer Singh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NonExistent\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{name}' -> '{evaluate(encoder, decoder, name)}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1-2885624437.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(encoder, decoder, sentence, max_length)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0minput_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-2885624437.py\u001b[0m in \u001b[0;36mtensor_from_text\u001b[0;34m(lang, text, max_length)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Helper to convert text to indices tensor, with padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensor_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add EOS token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Truncate if too long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1-2885624437.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Helper to convert text to indices tensor, with padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensor_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Add EOS token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Truncate if too long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'E'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the vocabulary size (number of unique words/items)\n",
        "vocab_size = 1000  # Example: 1000 unique words\n",
        "\n",
        "# Define the embedding dimension (size of each embedding vector)\n",
        "embedding_dim = 128 # Example: Each word will be represented by a 128-dimensional vector\n",
        "\n",
        "# Create the embedding layer\n",
        "# nn.Embedding(num_embeddings, embedding_dim)\n",
        "# num_embeddings: size of the dictionary of embeddings (vocab_size)\n",
        "# embedding_dim: the size of each embedding vector\n",
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "# Example input: a tensor of indices representing words/items\n",
        "# These indices would typically come from a pre-processed dataset\n",
        "# For example, a sequence of word IDs in a sentence\n",
        "input_indices = torch.tensor([\n",
        "    [10, 25, 50, 75],  # First sequence of indices\n",
        "    [100, 200, 300, 400] # Second sequence of indices\n",
        "])\n",
        "\n",
        "# Pass the input indices through the embedding layer\n",
        "# This will perform a lookup and return the corresponding embedding vectors\n",
        "output_embeddings = embedding_layer(input_indices)\n",
        "\n",
        "# Print the shape of the output embeddings\n",
        "# Expected shape: (batch_size, sequence_length, embedding_dim)\n",
        "print(f\"Shape of input indices: {input_indices.shape}\")\n",
        "print(f\"Shape of output embeddings: {output_embeddings.shape}\")\n",
        "\n",
        "# Print a sample of the output embeddings (e.g., the first embedding)\n",
        "print(f\"First embedding vector from the output: {output_embeddings[0, 0]}\")"
      ],
      "metadata": {
        "id": "nFjNLo3baUUK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}